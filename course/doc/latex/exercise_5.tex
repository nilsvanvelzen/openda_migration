We start with some single and ensemble runs to understand where for our black
box wrapper configuration the model results appear:
\begin{itemize}

 \item Run the model within OpenDA by using
   the \\{\tt SequentialSimulation.oda} configuration. Use the script  {\tt plot\_movie\_seq.py} to visualize the model 
   results. Compare the results with
   those from the run you executed without using OpenDA. 
 \item Run an ensemble forecast model by using the \\{\tt
   SequentialEnsembleSimulation.oda} configuration. On which variable does the
   algorithm impose stochastic forcing?\\ Have a look at the {\tt
     stochModel/output} directory, and note that the black box wrapper created
   the required ensemble members by repeatedly copying the template directory
   {\tt stochModel/input} to\\ {\tt stochModel/output/work\textless
     N\textgreater}.
 \item Compare the result between the mean of the ensemble and the results from {\tt
     SequentialSimulation.oda}. Note the relatively large differences. Check if
   these differences are reduced by increasing the ensemble size for the
   sequential ensemble simulation to 20 and rerunning {\tt
     SequentialEnsembleSimulation..oda} (this run may take a few minutes).
     You can use the script {\tt plot\_movie\_enssim.py}.
\end{itemize}

Now let us have a look at the configuration for performing OpenDA's Ensemble
Kalman Filtering on our black box model, using a twin experiment as an example.
The model has been run with the 'real' values (time dependent)for the
concentrations for substance 1 as disposed by factory 1 and factory 2. This
'truth' stored in the directory {\tt truthmodel}, and the results of that run
have been used to generate observation time series at the output locations.
These time series have been copied to the {\tt stochObserver} directory to
serve as observations for the filtering run.

The filter run takes the original model as input, which actually is a perturbed
version of the 'truth' model: the concentrations for substance 1 as disposed by
factories have been flattened out to a constant value. The filter process
should modify these values in such a way that the results resemble the truth as
much as possible.

To do this the filter modifies the concentration at factory 2, and uses the
observations downstream of factory 2 to optimize the forecast.

\begin{itemize}
 \item Note that the same black box configuration is used for the sequential
   run, the sequential ensemble run, and for the EnKF run. Identify the part of
   the {\tt polluteStochModel.xml} configuration that is used only by the EnKF
   run, and not by the others.
 \item Execute the Ensemble Kalman Filtering run by using the {\tt EnKF.oda}
   configuration.\\ Check how good the run is performing, by analyzing to what
   extent the filter has adjusted the predictions towards the
   observation.\\ Note that the model output files in {\tt
     stochModel/output/work0} only contains a few time steps. Can you explain
   why?\\ So to compare the observations with the predictions you have to use
   the result file produced by the EnKF algorithm which can be visualised using
   {\tt plot\_movie.py}.
\end{itemize}

Now let us extend the filtering process by incorporating also the concentration
disposed by factory 1, and by including the observation locations downstream of
factory 1.

\begin{itemize}
 \item Make a copy of the involved config files, {\tt EnKF.oda} and \\{\tt
   polluteStochModel.xml} (you could call them {\tt EnKF2.oda} and\\ {\tt
   polluteStochModel2.xml}.\\ Adjust {\tt EnKF2.oda} so that it refers to the
   right stochastic model config file and produces a matlab result file with a
   recognizable name, e.g. {\tt enkf\_results2.m}.
 \item Now adjust {\tt polluteStochModel2.xml} in such a way that the filtering
   process is extended as described above.
 \item Run the filtering process by using the {\tt EnKF2.oda} configuration,
   and compare the results with the previous version of the filtering process.
\end{itemize}

